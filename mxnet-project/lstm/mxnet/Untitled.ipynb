{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min len:  10\n",
      "max len:  2459\n",
      "avg len:  230.51952\n",
      "X_train: \n",
      "[[  3.20000000e+01   6.46100000e+03   2.51000000e+03 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  2.44000000e+02   3.50000000e+01   4.40000000e+01 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  6.90000000e+01   1.00000000e+00   1.60000000e+01 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  9.00000000e+00   8.80000000e+01   1.15000000e+02 ...,   2.33100000e+03\n",
      "    9.00000000e+00   6.70000000e+01]\n",
      " [  9.99900000e+03   9.99900000e+03   4.40000000e+01 ...,   1.00000000e+00\n",
      "    1.11000000e+02   1.56000000e+02]\n",
      " [  5.92000000e+02   3.33000000e+02   1.00000000e+00 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "<NDArray 25000x250 @gpu(0)>\n",
      "X_test: \n",
      "[[  1.39900000e+03   2.58300000e+03   8.40000000e+02 ...,   1.00000000e+00\n",
      "    3.75700000e+03   2.00000000e+00]\n",
      " [  9.00000000e+00   2.31000000e+02   5.10000000e+01 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  9.00000000e+00   1.20000000e+01   4.10000000e+01 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " ..., \n",
      " [  9.00000000e+00   4.17000000e+02   9.99900000e+03 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.33000000e+02   1.72000000e+02   4.60000000e+01 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]\n",
      " [  1.40000000e+02   2.00000000e+01   2.43000000e+02 ...,   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00]]\n",
      "<NDArray 25000x250 @gpu(0)>\n",
      "Y_train: \n",
      "[ 1.  0.  1. ...,  1.  0.  0.]\n",
      "<NDArray 25000 @gpu(0)>\n",
      "Y_test: \n",
      "[ 1.  1.  1. ...,  0.  0.  0.]\n",
      "<NDArray 25000 @gpu(0)>\n",
      "train len: 25000\n",
      "test len: 25000\n"
     ]
    }
   ],
   "source": [
    "from pre_processing import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet import gluon, nd, autograd\n",
    "from mxnet.gluon import nn, rnn\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(train_data, train_all_labels, test_size=0, random_state=42)\n",
    "#x_train = train_data\n",
    "#y_train = train_all_labels\n",
    "\n",
    "x_test = test_data\n",
    "y_test = test_all_labels\n",
    "\n",
    "# divide 30% of data into test data\n",
    "#x_train, x_test, y_train, y_test = train_test_split(train_data, train_all_labels, test_size=0.99, random_state=42)\n",
    "#x_test, x_train, y_test, y_train = train_test_split(train_data, train_all_labels, test_size=0.3, random_state=42)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(all_data, all_labels, test_size=0.5, random_state=42)\n",
    "#x_train, x_test, y_train, y_test = train_test_split(all_data, all_labels, test_size=0.5, shuffle=False)\n",
    "\n",
    "\n",
    "# print (\"check??\")\n",
    "# print ( x_train[0] )\n",
    "# print ( x_test[0] )\n",
    "\n",
    "# some statistics\n",
    "min_len = min(map(len, train_data))\n",
    "max_len = max(map(len, train_data))\n",
    "avg_len = sum(map(len, train_data)) / len(train_data)\n",
    "\n",
    "print(\"min len: \", min_len)\n",
    "print(\"max len: \", max_len)\n",
    "print(\"avg len: \", avg_len)\n",
    "\n",
    "seq_len = 250 # set the max word length of each movie review\n",
    "\n",
    "# if sentence is greater than max_len, truncates\n",
    "# if less, pad with value\n",
    "def pad_sequences(sentences, max_len=500, value = 0):\n",
    "    padded_sentences = []\n",
    "    for sentence in sentences:\n",
    "        new_sentence = []\n",
    "        if (len(sentence) > max_len):\n",
    "            new_sentence = sentence[:max_len]\n",
    "            padded_sentences.append(new_sentence)\n",
    "        else:\n",
    "            new_sentence = np.append(sentence, [value]*(max_len-len(sentence)))\n",
    "            padded_sentences.append(new_sentence)\n",
    "\n",
    "    return padded_sentences\n",
    "\n",
    "context = mx.gpu()\n",
    "X_train = nd.array(pad_sequences(x_train, max_len=seq_len, value=0), context)\n",
    "X_test = nd.array(pad_sequences(x_test, max_len=seq_len, value=0), context)\n",
    "Y_train = nd.array(y_train, context)\n",
    "Y_test = nd.array(y_test, context)\n",
    "\n",
    "print(\"X_train: \" + str(X_train))\n",
    "print(\"X_test: \" + str(X_test))\n",
    "\n",
    "\n",
    "print(\"Y_train: \" + str(Y_train))\n",
    "print(\"Y_test: \" + str(Y_test))\n",
    "\n",
    "print( \"train len: \" + str(len(X_train)))\n",
    "print( \"test len: \" + str(len(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## define network\n",
    "num_classes = 2\n",
    "num_hidden = 64\n",
    "learning_rate = .01\n",
    "epochs = 50\n",
    "batch_size = 12\n",
    "\n",
    "model = nn.Sequential()\n",
    "with model.name_scope():\n",
    "    model.embed = nn.Embedding(voca_size, num_embed)\n",
    "    model.add(rnn.LSTM(num_hidden, layout = 'NTC', dropout=0.3, bidirectional=True))\n",
    "    model.add(nn.Dense(num_classes))\n",
    "\n",
    "def eval_accuracy(x, y, batch_size):\n",
    "    accuracy = mx.metric.Accuracy()\n",
    "    sum = 0\n",
    "    for i in range(x.shape[0] // batch_size):\n",
    "        data = x[i*batch_size:(i*batch_size + batch_size), ]\n",
    "        target = y[i*batch_size:(i*batch_size + batch_size), ]\n",
    "\n",
    "        output = model(data)\n",
    "        predictions = nd.argmax(output, axis=1)       \n",
    "        \n",
    "        accuracy.update(preds=predictions, labels=target)\n",
    "        \n",
    "    return accuracy.get()[1]\n",
    "\n",
    "model.collect_params().initialize(mx.init.Xavier(), ctx=context)\n",
    "#model.collect_params().initialize(mx.init.Normal(sigma=1,), ctx=context)\n",
    "\n",
    "model.embed.weight.set_data(embedding_matrix.as_in_context(context))\n",
    "\n",
    "trainer = gluon.Trainer(model.collect_params(), 'sgd',\n",
    "                        {'learning_rate': learning_rate})\n",
    "\n",
    "softmax_cross_entropy = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    for b in range(X_train.shape[0] // batch_size):\n",
    "        data = X_train[b*batch_size:(b*batch_size + batch_size),]\n",
    "        target = Y_train[b*batch_size:(b*batch_size + batch_size),]\n",
    "\n",
    "        data = data.as_in_context(context)\n",
    "        target = target.as_in_context(context)\n",
    "\n",
    "        with autograd.record():\n",
    "            output = model(data)\n",
    "            L = softmax_cross_entropy(output, target)\n",
    "        L.backward()\n",
    "        trainer.step(data.shape[0])\n",
    "    #if epoch % 2 == 0 :    \n",
    "        #filename = \"lstm_net.params\" +\"_\"+ str(epoch)\n",
    "        #model.save_params(filename)\n",
    "    test_accuracy = eval_accuracy(X_test, Y_test, batch_size)\n",
    "    train_accuracy = eval_accuracy(X_train, Y_train, batch_size)\n",
    "    print(\"Epoch %s. Train_acc %s, Test_acc %s\" %\n",
    "          (epoch, train_accuracy, test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model definition\n",
    "net2 = gluon.nn.Sequential()\n",
    "\n",
    "with net2.name_scope():)\n",
    "    \n",
    "# load weights\n",
    "net2.load_params(filename, ctx=ctx)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mxnet_p36]",
   "language": "python",
   "name": "conda-env-mxnet_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
